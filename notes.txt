# ===============================================================================================================================================

Historia.

Hadoop ocupa el modelo MapReduce (MapeoReducciÃ³n) y dos de sus limitaciones son:

    ğŸ”¸ Rendimiento: Es lento por que escribe resultados intermedios en disco.
    ğŸ”¸ Flexibilidad: No es ideal para tareas iterativas (e.g. ml) o flujos cÃ­clicos, ya que su diseÃ±o es inherentemente acÃ­clico.

Modelo en Spark â­: RDDs y DAGs.

1. RDDs (Resilient Distributed Datasets):

RDDs es una abstracciÃ³n de datos distribuidos y tolerate a fallos. Un RDD es una collecciÃ³n de elementos particionados que se pueden procesar en paralelo a travÃ©s de un clÃºster.

Propiedades:

    ğŸš€ Inmutables: No se modifican una vez creados.
    ğŸš€ Resilientes: Si un nodo falla, Spark â­ puede reconstruir los datos perdidos gracias a un linaje (historia de transformaciones).
    ğŸš€ En memoria: Los RDDs se almacenan en la RAM siempre que sea posible, lo que reduce la dependencia de lecturas/escrituras en disco.

Operaciones:

    ğŸ“Œ Transformaciones: Crean un nuevo RDD a partir de uno existente (e.g., map, filter). Son "lazy" (no se ejecutan hasta que se necesita un resultado).

    ğŸ“Œ Acciones: Devuelven un resultado al programa o escriben datos (e.g., count, collect).

2. DAG (Directed Acyclic Graph).

DAGs en Spark â­ construye un grafo acÃ­clico dirigido que representa la secuencia de transfomaciÃ³n aplicada a los datos. Este DAG describe el flujo de tragajo completo.

En lugar de forzar en dos etapas como MapReduce, Spark â­ optimiza el flujo de datos permitiendo mÃºltiples Transformaciones consecutivas sin necesidad de escribir resultados intermedios en disco.

Ejemplo: Si filtras datos, los agrupas y luego los sumas, Spark â­ crea un DAG con operaciones y lo ejecuta de forma eficiente en una sola pasada cuando se invoca una acciÃ³n.

# ===============================================================================================================================================
// Cuando creagmos un singlenton se ejecuta en REPL:
scala > object.main(Array())

// Si creamos una clase se ejecuta en REPL:
scala > main(Array())


